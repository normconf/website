
<!DOCTYPE html>
<html>

<head>
  <title>Normconf: Data's desire paths: shortcuts and lessons from industrial recommender systems -  James Kirk Transcript</title>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="description"
    content="Transcript of Data's desire paths: shortcuts and lessons from industrial recommender systems -  James Kirk from Normconf" />
  <meta property="og:title" content="Normconf: Data's desire paths: shortcuts and lessons from industrial recommender systems -  James Kirk Transcript" />
  <meta property="og:url" content="https://normconf.com" />
  <meta name="og:description"
    content="Transcript of Data's desire paths: shortcuts and lessons from industrial recommender systems -  James Kirk from Normconf" />
  <meta property="og:image" content="https://normconf.com/images/normconf_banner_metadata_1000x500.png" />
  <meta property="og:type" content="website" />
  <meta name="twitter:image" content="https://normconf.com/images/normconf_banner_metadata_1000x500.png" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="normconf.com" />
  <meta name="twitter:creator" content="@normconf" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <link href="fontawesome/css/all.min.css" rel="stylesheet">
  <link rel="icon" type="image/x-icon" href="images/favicon.ico">
  <style>
    body {
      background-image: url('images/background_placeholder.png');
    }

    .hero {
      background-color: None;
      color: #797979;
      font-family: sans-serif;
    }

    .center {
      display: block;
      margin-left: auto;
      margin-right: auto;
      width: 50%;
    }

    a:link {
      color: #4200be;
    }

    a:visited {
      color: #4200be;
    }

    a:active {
      color: #ef028c;
    }

    a:hover {
      color: #ef028c;
    }

    a.light_link:link {
      color: #ef028c;
    }

    a.light_link:visited {
      color: #4200be;
    }

    a.dark_link:link {
      color: #ef028c;
    }

    a.dark_link:visited {
      color: #ef028c;
    }

    a.dark_link:active {
      color: #5fffcf;
    }

    a.dark_link:hover {
      color: #5fffcf;
    }

    a.on_pink:link {
      color: #5fffcf;
    }

    a.on_pink:active {
      color: #6017af;
    }

    a.on_pink:hover {
      color: #4200be;
    }

    .navbar.is-dark .navbar-end>a.navbar-item:hover {
      background-color: #ef028c;
    }

    .navbar.is-dark .navbar-item {
      white-space: normal;
    }

    .navbar.is-dark .navbar-item.has-dropdown:hover .navbar-link {
      background-color: #ef028c;
    }

    .navbar.is-dark .navbar-brand>a.navbar-item:hover {
      background-color: #6017af;
    }

    .button.is-danger {
      background-color: #ef028c;
    }

    .button.is-primary {
      background-color: #5fffcf;
      color: #4200be;
    }

    table.speakers1 {
      font-weight: bold;
      color: #4200be;
      width: auto;
    }

    table.speakers2 {
      font-weight: bold;
      color: #6017af;
      width: auto;
    }

    table.schedule {
      font-weight: bold;
      /* width: auto; */
    }

    table.schedule td {
      text-align: center;
      padding: 0.5em;
      max-width: 30em;
      /* word-wrap: break-word; */
    }

    table.schedule tr:nth-child(odd) {
      color: #4200be;
      background-color: #00000017;
    }

    table.schedule tr:nth-child(even) {
      color: #6017af;
    }

    .message.is-primary .message-header {
      background-color: #5fffcf;
      color: #4200be;
    }
  </style>
  </head>
  <body>
  <section class="section" style="background-color: #6017af;">
    <div class="container">
    <div class="box">
      <h1 class="title">
        Data's desire paths: shortcuts and lessons from industrial recommender systems -  James Kirk
      </h1>
      <p class="subtitle">
        Transcript generated with <a href='https://github.com/openai/whisper'>OpenAI Whisper</a> <code>large-v2</code>.
      </p>
      </div>
      <div class="box">
        <a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=0">I'm James Kirk. I was one of your MCs this morning, if any of you are still awake after </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=5">the early start today. But I'm back and I wanted to tell you a bit about a subject that </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=10">I really, really love. And I've gotten to work on a bunch, which is recommender systems, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=15">and particularly a lot of the ways that building recommender systems can get really thorny </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=20">and challenging and also a lot of fun. And my favorite way to rationalize recommender </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=27">systems is as a desire path. If you're familiar with these, the desire path is what happens </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=33">when a whole bunch of people all decide to walk through a field in the same way to get </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=38">from point A to point B. And eventually the grass dies and you get a bit of a trail. And </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=43">sometimes people will come along after and say, all right, well, if people always wanted </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=47">to get from point A to point B there, then maybe we should pave it, pave it. Maybe that's </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=51">where the path should always have been. I think this is kind of a neat metaphor for </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=54">recommenders themselves for kind of an obvious reason, right? Like people like to get from </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=58">A to B, it's your job, the recommender systems job to get them from A to B. But I also think </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=64">when you go a little one level, a little more abstract when you're building systems like </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=68">recommender systems or ML systems in general, this is kind of how you should think about </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=73">your process of building them from scratch, developing them, iterating on them, getting </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=78">them out into production and making something that you actually can leave behind to continue </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=83">to iterate on for your peers going forward. So a bit about me. My name is James Kirk. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=91">That's what I looked like when I had longer hair and was therefore a bit cooler. I'm the </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=95">co-founder of Meru. We're building some new ways to recommend with humans, particularly </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=100">content creators in the loop to make recommendations to people who follow them. Previously, I worked </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=105">at Spotify, bulk of my career at Spotify, working on recommenders there and also at </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=110">a couple of other companies around Boston and also a stint at Amazon. But today, you're </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=117">not really here to learn about me. I want to tell you a story about you. This might </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=121">be a bit familiar to some of you if you've built recommender systems before, because </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=126">you're an engineer, you're a data scientist at your company. You've been there a while. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=130">You've been working on a couple of different projects. You've gotten familiar with the </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=134">tech stack, the data. You've put some ML models in prod. And then one day this word comes </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=140">from above and somebody opened up TikTok and discovered something really cool and wanted </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=146">to know why they can't build that or can we build that or why haven't we already built </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=151">that and how do we get there? How do we get recommendations like some of these products, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=156">especially consumer products that tons and tons of people are engaging with? This can </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=161">probably make the hair on the back of your neck stand up the first time you hear it. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=164">But I think it's also a really great opportunity because this can be a really fun space to </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=169">dig into if you've never built recommender systems before, as long as you know some of </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=174">the pitfalls that you're going to want to avoid. The first and most salient one is probably </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=179">very simply from the origin here that most recommender projects from the get go are poorly </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=185">framed. By poorly framed, I mean that the idea hasn't really been fleshed out to a </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=191">degree that gives you, the engineer or data scientist, enough clarity to develop something </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=195">that will be healthy either in the short or the long term. Now, when this comes from above, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=200">this isn't necessarily leadership's fault because they might absolutely have the right </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=203">idea that the business has data that could be used in such a way to really delight your </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=208">users and it's strategically valuable to build recommender systems and improve your product </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=214">with them. But maybe there's a lot of really loose concepts or inspirations flying around </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=218">about how that recommender might really work. And when that's really amorphous, it can be </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=222">really challenging to actually build those systems and get them out into the real world. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=227">Just as often, these poor framings come from the bottom up. Sometimes somebody reads the </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=231">new paper from the Rexis conference and it's super cool and flashy and they want to stick </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=235">the transformers into the loop of their data somewhere. And then what does that look like? </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=239">Maybe it's recommenders, et cetera, et cetera. It becomes technology or a solution in search </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=243">of a problem. That's just as thorny and it's also your job if you're working around them </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=247">to figure out how to take that idea, which might be perfectly aligned in the long term </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=251">to something really wonderful and valuable and form it into a project that will actually </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=255">be healthy. So you're in the jungle now. Pitfalls abound. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=261">You have just crossed the first one because you, or at least you see the first one coming, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=266">which is around the problem framing. And if your company has never built recommenders </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=270">before, there probably really are no desire paths for you here. There's not an organizational </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=276">necessarily competency around what these projects look like, how to develop them, how to iterate </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=280">on them, how to maintain them long-term. And it's your job on this team to just get it </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=285">right the first time. Get it right the first time, not perfectly, not a perfectly well-paved </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=290">highway for the team to be sending a thousand models and experiments down or anything, but </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=294">start to carve that path in a way that other people would actually be able to follow in </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=298">the future. When you're framing this and you want to make </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=303">sure it's a healthy project, I think there are really four things that you got to look </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=306">for. And these are often missing when the idea to build recommender systems first come </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=311">up. The first and most salient in my mind is a clearly defined user. Does this matter </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=316">to your customer, to the user, to the person who's going to be receiving recommendations? </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=320">And on top of that, do you have any specificity about what their needs really are? Is this </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=325">somebody who will actually respond to recommendations, wants recommendations in their product and </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=330">will get value out of them? A big misalignment that often happens is that there will be a </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=337">different group of users that maybe one party like leadership sees as the recipient of recommenders </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=343">versus maybe product management might see things differently. Maybe executives, they're </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=347">looking at the strategy and they're saying, all right, it's got to be for 1824s in the </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=350">US that are casual users and we want to make sure they're experienced perfect. And then </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=355">product is saying, oh, it's going to be perfect for everybody. Our algorithms need to understand </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=358">every single user, cold starts need to be perfect, et cetera. You need to help get people </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=363">aligned on who exactly this clearly defined user is going to be. Otherwise the waters </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=367">are already choppy. Next up is a measurable definition of success. When you build this </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=373">system, this product, and you put it in users' hands, how will you know if it's any good? </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=378">In plain English, how will you know if it's any good? How will you know that people's </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=381">experience is delightful? And also quantitatively, do you have metrics that will tell you that </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=386">users are responding well to recommendations? And if not, how can you develop those metrics? </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=392">The burden is often on you as engineering or data science to help define this metric </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=398">of success, both in plain language, as well as quantitatively. And you need to make sure </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=403">that all these stakeholders are also aligned about what that definition is. Next up is </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=408">that you need somebody to be able to tell you in clear language, why that matters. Why </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=413">does it matter to your business, to your organization, that that recommendation is successful? There </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=418">are a lot of projects that create really great recommendations. They're really delightful </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=422">for people, but are unable to actually drive value for the business, and they languish. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=427">And sometimes this is how these passion projects die. They never get in front of enough people </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=431">that they could have if they also had a clear relationship to what makes the business successful. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=435">So seek that out and make sure that especially leadership of a recommender project understand </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=439">that relationship. Last, and this is squarely your domain as data and engineering, is make </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=444">sure that the data and tech stack that the company have are ready to build some kind </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=448">of recommendation systems. Nobody wants to get into a project where you have to tell </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=451">them, okay, well, we need six months of explicit feedback data collection to even dream of </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=456">starting a recommender here. Make sure that what these concepts look like, look like something </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=461">you can deliver with the data and tech stack your company has. So this, I consider kind </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=467">of the first shortcut is just crisping up the requirements, which doesn't really feel </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=470">like a shortcut. It feels like more work, right? But the reason it's a shortcut is because </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=474">it keeps you from going in circles here. There are projects that can go on and on and on </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=478">just trying to crisp up what the actual real world definition of success is, or they can </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=483">go on and on and on trying to eventually get to the right data to implement recommendations. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=487">And if you make sure that everybody's crisp and aligned on what those last four points </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=491">were before you start the engineering, you're in a much better situation to just drive through </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=495">and start building things that will drive value for local users. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=502">As you're crisping up these requirements, you're going to also start to figure out that </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=505">there's a lot of different flavors of recommendation and ways that it could work. One of them is </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=510">your classic flat recommendation. This is not personalization or anything fancy like </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=516">infinite fees. This is just you are here, you're looking at, if you're me, you're looking </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=520">at my monthly batch of beard butter, and you're getting recommendations of things that I might </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=525">also want to buy. To be able to make these recommendations, Amazon doesn't need any information </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=529">about me. There's no database table saying James has a beard or anything about James, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=533">but just the context, just by being on this page, they know something about me that then </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=538">is useful for making these recommendations. So knowing that you don't need to know much </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=542">about these or to make these recommendations tells you a lot about what you need to build </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=545">to satisfy them. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=547">The next layer deep is when you start to go into real personalization. These tend to be </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=552">products that they're reflecting the user based off of the interactions that they've </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=556">had in the past. This means that we need to engineer for the interaction data and for </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=561">user data to be accounted for in the recommender system. One of the ways that you kind of know </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=566">personalization systems are what's on the horizon for you is when it's not just about </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=570">the algorithms, but it's about the copy. What are you saying about the recommendations? </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=574">Are you saying it's for you? Is Spotify with the Discover Weekly, they're saying it's your </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=579">weekly mixtape. The UUU is telling you a lot about what the user expectations will be. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=584">And so if design, copy, product are all telling you that top picks for James and your weekly </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=589">mixtape are critical components, you know, you're talking personalization, which means </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=593">you know, you're talking user data and interaction data. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=596">And another flavor of this is called omakase recommendation. Omakase is a Japanese word </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=602">meaning I think chefs or you choose something like that. And often used in sushi. It's, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=608">you know, chef's choice. You take it away. You see this a lot in these infinite feed </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=612">style recommendations where there's not really like a framing or copy or anything. You just </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=617">dive in and you get some content and it just keeps flowing. It just keeps going. You also </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=622">see this a lot when you're working with voice assistants. When you see something like, hey, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=626">I'm not going to say it because otherwise I'll probably trigger a couple hundred of </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=628">them. Hey, blank play music. That kind of thing is very, you know, it's a very loosely </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=634">formed request for recommendations, but the system underneath it needs to be able to satisfy </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=640">that satisfy usually a very long session of that at consistent quality. And that's a very </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=645">high bar for the recommender systems and data underneath. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=649">So get crisp about which one of these you're actually building. Make sure that you in engineering, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=654">make sure that product user research, design leadership are all aligned about which one </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=659">of these you're building. Make sure that you have a really strong hypothesis that this </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=662">is what the customer really wants, especially when you're starting from scratch. Has user </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=666">research indicated this is something that would delight them? Have prototypes or mockups </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=670">been shown to users that give you some feedback about how it will be received? And most importantly, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=676">when you've launched this, how will you actually know that you've succeeded? How will you know </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=680">that this is delightful for the users that are receiving it? </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=684">So now that it's starting to solidify, you might start feeling like this, this recommender </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=689">system that's crystallizing in front of you, starting to feel a lot like search. Search </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=694">is a very, very similar field to recommender systems. There are a lot of things that overlap </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=700">between the two, but a very, very important thing to keep in mind here, especially for </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=705">somebody who has experience in search, just that they're not quite the same. And those </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=710">not quite bits are where all the lift really is going to come from. When you're able to </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=716">take things that come off the shelf from search and apply them, knowing the ways that recommender </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=721">problems and products are different, that can be really, really powerful. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=724">But keep in mind that they're not quite the same. There's good news though. I mean, they </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=729">are pretty close and that's a really great shortcut because search is quite mature. Lots </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=734">of organizations do have a competency in search. They have search technology. There's off the </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=740">shelf search tools that you can apply to recommender problems if you know how to apply them and </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=745">put them together in a way that builds a healthy recommender system. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=749">The most similar thing between search and recommendations is generally that you're retrieving </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=753">from a large set of candidates. Search is looking through millions of documents. Recommendations </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=758">are searching through millions of items and you're trying to come up with a couple of </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=761">the right things to show to somebody. But often that's about as deep as the similarities </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=765">go. That's where they start to diverge a bit. On the search side, users are generating a </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=770">query. They're telling you something that they want and it's your job to satisfy that. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=774">On the recommendation side, it's a little fuzzier. The user, the context they're in, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=779">their history, all kinds of things kind of become the query, but you kind of have to </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=783">squint to look at it to call it a query. You end up constructing things that look a lot </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=788">like queries and can then run through search style systems like queries. But keep in mind </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=793">again, this isn't explicit somebody asking for something and that can often lead you </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=798">into trouble if these queries are poorly constructed. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=803">And search, you tend to be optimizing for the first couple of things that you're retrieving </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=807">for the user. You want to get those first few results right because the person came </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=811">in looking for something and you need to get it for them. Recommendations, that applies. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=816">You still want the first couple of recommendations to be good pretty much all the time. You get </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=819">a lot of other factors that start to really impact recommendations. You get slate diversity. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=825">How broad are my recommendations that I'm seeing on this shelf? You get novelty. Am </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=829">I seeing the same things every time I interact with these recommendations? You get interactivity. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=834">If somebody is giving you a thumbs up or a thumbs down on something that they liked or </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=837">didn't like, are you responding to that in a way that makes sense to the user? These </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=841">things that you're optimizing for are where recommendations in search tend to really, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=845">really diverge. So if you're somebody who is experienced building search systems, you </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=851">probably are starting to feel like, oh, okay, I kind of recognize how recommender systems </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=855">work. All I have to do is take what I know, break it down into its constituent bits, and </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=860">put them all back together again to make something new. This means that you're pretty well positioned </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=865">to be effective at building recommender systems. You have a lot of these bits of knowledge </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=870">and competencies. The biggest risk is kind of staying in your own way at keeping RECs </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=875">thinking about them just as search problems. I would recommend that you just consistently </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=880">re-anchor yourself. Remember that recommendations are a different kind of user experience. Think </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=885">about how your user is receiving them and why that's not quite search. And then I think </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=889">you are going to blow people away with the things that you're able to apply from the </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=892">search domain to recommendations. Use these Legos, but make sure you remember that you're </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=897">putting together something totally different than what you've done before. A colleague </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=902">of mine named Carl said this recently. He tutored it over on Mastodon, that Rexis, it </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=908">is quite similar to search, to information retrieval, except there's a lot of nuance </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=913">that goes into building that quote-unquote query about the user. This is a lot of the, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=918">for lack of a better word, artistry of building recommender systems, and it's where a lot </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=922">of people get lost when they're coming from search over to recommendations. The second </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=927">place that people sometimes get really tangled up in recommendations is simply that the offline </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=933">metrics for recommender systems tend to just be kind of bad. They're a little misleading. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=938">They don't tell us really what we think they're telling us, and a lot of them are borrowed </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=942">from adjacent fields like search or other areas of information retrieval, but they don't </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=946">quite apply squarely to recommenders. If you've worked in search or recommenders, you might </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=952">be familiar with NDCG. By the way, I promise this is the one equation the whole slide is </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=956">showing. NDCG is a very commonly used metric. It's effectively saying how good are the top </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=961">few recommendations and how high have we packed the really good stuff in that recommendation </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=965">set. It works really nicely in a lot of problems. You know it's fancy because it's got Greek </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=970">letters in it. I know that sigma is not one of the fancy, fancy Greek letters, but we'll </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=973">still give it some credit. It's often applied to recommender systems because it's very commonly </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=977">used in the search systems, and there are a lot of tools available for it. You've probably </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=983">trained up a recommender system offline. You have a bunch of data about historical user </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=987">reactions. You can calculate NDCG, and it gives you a number that tells you something </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=990">that looks like my algorithm is good or my algorithm is bad. Then you're going to start </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=995">to run some of these algorithms online. You're going to start to collect online feedback </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1000">data about which of these algorithms are good and bad. What I am advocating for you to do </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1004">is to plot it. Just plot it. Just take the offline scores that these metrics, especially </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1010">the borrowed ones, are telling you, and for every algorithm, plot on the scatter where </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1015">that offline metric told you that that algorithm performed and where an online metric, something </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1021">that really is about user satisfaction with the recommender system, what that tells you </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1025">about how good those recommendations were. You probably expect it to look something like </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1030">this. Your algorithm is, you start with something truly random, that pink dot. It's not very </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1036">good for offline metrics, and it's not very good online because it's just a bunch of random </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1039">ranked stuff, but your better offline metrics, they start to get better and better online. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1044">Maybe there's some diminishing returns there, but generally, you have some responsiveness. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1049">More often than not, when you first start a project, you will find that your offline </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1053">metric gives you no response whatsoever in your online metric. There are big, big changes </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1058">in the offline performance that might not have any appreciable impact in the online </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1063">performance of your recommender, and there are dozens of causes. It could be the product </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1066">itself. It might not be sensitive to these changes. It might just be that users aren't </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1070">really responding to these changes. Maybe the product just is poorly framing the recommendations, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1074">so how good the algorithm is doesn't matter, but don't be surprised if you see a chart </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1078">like this. Also, don't be surprised if you see a chart like this. Sometimes what you'll </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1083">find is your random treatment, when you're truly just picking random stuff, it's not </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1087">good, but all of your recommenders are much better online, but the sensitivity within </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1092">that is very, very poor. What that's kind of telling you is that there's not much headroom </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1097">to be gained online from just squeezing more and more and more NDCG out of your algorithms </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1102">offline. This probably tells you that NDCG is the wrong metric for your problem, and </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1106">you're going to want to find some new way offline to measure how good your recommendations </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1110">are, and you should experiment to find those right metrics. So there's another shortcut </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1115">for you. Just design those first experiments, not for the best algorithm to go out online, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1120">although you'll maybe have some serendipity there, but design them to validate your experimental </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1124">methodology itself. Make sure that your metrics matter, and make sure that you're going to </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1128">be able to actually cut through this hedge maze, or you could get lost in it forever, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1132">squeezing more NDCG out in a way that just truly never matters. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1136">Just real quick one for you is just does it scale, and does it need to? In a lot of cases, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1143">especially when you're prototyping recommender systems, you actually don't have the kinds </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1147">of scale problems that you would expect if you were going to production or full scale, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1151">and often a lot of very simple solutions will give you everything you need to experiment. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1155">A little story here, we built Spotify's first podcast recommender. This was like five years </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1160">ago. This model's long dead. And when I built it, there were only 10 million podcast listeners </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1167">on all of Spotify, and only 10,000 podcasts. Spotify had very mature systems for running </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1173">recommenders, but we just kept it simple. We ran one Python script on one big box, dumped </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1179">10 recommendations per user to Bigtable, and serve them on the homepage. And this scaled </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1183">for about half a year as both of those numbers doubled. So just keep in mind that often scale </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1189">can lead you to thinking that you need to go with a lot of technologies that aren't </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1193">really improving your speed of iteration, and the simple stuff lets you iterate very </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1197">quickly. So just keep serving the simple stuff for as long as you can. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1203">So those are my four shortcuts for you, and my one last thought to leave you with is simply </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1207">to remember, and check a couple of this off your norm conf bingo, that recommender systems </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1212">are about people. They're about their behavior, what they want, what they need, what they </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1216">care. They're by people, you and the things that you think about content, about your users, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1220">are all getting baked into your system, and that can be good or bad, but they're for people. </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1224">You want to make people happy with the recommendations you're giving them. You want it to be delightful, </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1229">and that is what matters most. So thank you so much. If you disagree with anything, we </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1234">live in a beautiful age where you can yell at me on more platforms than ever. You can </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1237">find me at any of those, and I'd love to hear from you. And yeah, let me know if you have </a><a href="https://www.youtube.com/watch?v=Zoq0oHrGabc&t=1242">any questions. </a>
      </p>
    </div>
  </section>
  </body>
</html>